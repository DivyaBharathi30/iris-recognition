{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivyaBharathi30/iris-recognition/blob/main/iris_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D01Gd5w0NWL5",
        "outputId": "3412c257-d1cc-46d6-a8a5-88cbcc3da808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL2A6B7HQ8V7",
        "outputId": "ad3b401e-c362-41cc-83ee-22104609a722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.30 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 28.9/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v21eLeoHgSvZ",
        "outputId": "147f9016-9248-451b-9da0-04ed00743718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.30 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Found https://ultralytics.com/images/zidane.jpg locally at zidane.jpg\n",
            "image 1/1 /content/zidane.jpg: 384x640 2 persons, 1 tie, 179.2ms\n",
            "Speed: 5.9ms preprocess, 179.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download COCO val\n",
        "import torch\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d datasets && rm tmp.zip  # unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GasxfUrn9WA",
        "outputId": "175e68af-6775-40dc-8dca-39632ffbd9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780M/780M [00:10<00:00, 76.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate YOLOv8n on COCO8 val\n",
        "!yolo val model=yolov8n.pt data=coco8.yaml"
      ],
      "metadata": {
        "id": "QZ9d4CpsoKMW",
        "outputId": "4eefaff9-f3f1-415e-da79-4d1ad7ba674a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: yolo: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-FtfLXrxXrls"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qMLK5mUSblJ5"
      },
      "outputs": [],
      "source": [
        "image1 = cv2.imread(\"iris_image.jpg\")\n",
        "image2 = cv2.imread(\"iris_image_1.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zyVw8DZ5bttN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fe4a16-9dff-40dd-81db-ae38fbdda0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtpIkntsnxDa",
        "outputId": "485f6dc5-b8dd-465e-e049-142a367d2bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(image1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnz9Ai-kl_8A",
        "outputId": "42a1d90e-fecd-4713-c60f-e4f55cba3fec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 22  22  22]\n",
            "  [ 24  24  24]\n",
            "  [ 28  28  28]\n",
            "  ...\n",
            "  [ 55  55  55]\n",
            "  [ 53  53  53]\n",
            "  [ 53  53  53]]\n",
            "\n",
            " [[ 27  27  27]\n",
            "  [ 29  29  29]\n",
            "  [ 32  32  32]\n",
            "  ...\n",
            "  [ 53  53  53]\n",
            "  [ 51  51  51]\n",
            "  [ 51  51  51]]\n",
            "\n",
            " [[ 35  35  35]\n",
            "  [ 36  36  36]\n",
            "  [ 38  38  38]\n",
            "  ...\n",
            "  [ 54  54  54]\n",
            "  [ 53  53  53]\n",
            "  [ 53  53  53]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 81  81  81]\n",
            "  [ 90  90  90]\n",
            "  [ 94  94  94]\n",
            "  ...\n",
            "  [ 66  66  66]\n",
            "  [ 48  48  48]\n",
            "  [ 73  73  73]]\n",
            "\n",
            " [[ 71  71  71]\n",
            "  [ 83  83  83]\n",
            "  [ 91  91  91]\n",
            "  ...\n",
            "  [ 66  66  66]\n",
            "  [ 88  88  88]\n",
            "  [127 127 127]]\n",
            "\n",
            " [[ 70  70  70]\n",
            "  [ 91  91  91]\n",
            "  [ 93  93  93]\n",
            "  ...\n",
            "  [ 69  69  69]\n",
            "  [ 64  64  64]\n",
            "  [161 161 161]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sr5Vu5qn6FL",
        "outputId": "987d2e44-eac1-428a-ccea-f1b54a768b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 6  6  6]\n",
            "  [ 7  7  7]\n",
            "  [ 8  8  8]\n",
            "  ...\n",
            "  [50 50 50]\n",
            "  [49 49 49]\n",
            "  [47 47 47]]\n",
            "\n",
            " [[10 10 10]\n",
            "  [10 10 10]\n",
            "  [12 12 12]\n",
            "  ...\n",
            "  [52 52 52]\n",
            "  [50 50 50]\n",
            "  [49 49 49]]\n",
            "\n",
            " [[13 13 13]\n",
            "  [13 13 13]\n",
            "  [14 14 14]\n",
            "  ...\n",
            "  [52 52 52]\n",
            "  [50 50 50]\n",
            "  [48 48 48]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[45 45 45]\n",
            "  [45 45 45]\n",
            "  [45 45 45]\n",
            "  ...\n",
            "  [52 52 52]\n",
            "  [51 51 51]\n",
            "  [50 50 50]]\n",
            "\n",
            " [[45 45 45]\n",
            "  [45 45 45]\n",
            "  [45 45 45]\n",
            "  ...\n",
            "  [52 52 52]\n",
            "  [51 51 51]\n",
            "  [50 50 50]]\n",
            "\n",
            " [[46 46 46]\n",
            "  [45 45 45]\n",
            "  [45 45 45]\n",
            "  ...\n",
            "  [51 51 51]\n",
            "  [51 51 51]\n",
            "  [50 50 50]]]\n"
          ]
        }
      ],
      "source": [
        "print(image2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDxSrSbAvkvq",
        "outputId": "b8499a60-19a0-4950-ded9-d8433cdf0130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authorized\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the reference iris image (authorized)\n",
        "reference_image = cv2.imread('iris_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Load the probe iris image (to be verified)\n",
        "probe_image = cv2.imread('iris_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Preprocess the images (e.g., resize, normalize, enhance)\n",
        "def preprocess_image(image):\n",
        "    # Example: Resize the image to a standard size\n",
        "    resized_image = cv2.resize(image, (100, 100))\n",
        "    # You can add more preprocessing steps such as normalization or enhancement\n",
        "    return resized_image\n",
        "\n",
        "reference_image_processed = preprocess_image(reference_image)\n",
        "probe_image_processed = preprocess_image(probe_image)\n",
        "\n",
        "\n",
        "# Extract features from the images\n",
        "def extract_features(image):\n",
        "    # Example: Perform circular Hough transform to detect iris boundary\n",
        "    circles = cv2.HoughCircles(image, cv2.HOUGH_GRADIENT, dp=1, minDist=50,\n",
        "                               param1=100, param2=30, minRadius=10, maxRadius=80)\n",
        "\n",
        "    if circles is not None:\n",
        "        # Sort circles by radius\n",
        "        circles = np.uint16(np.around(circles))\n",
        "        circles = sorted(circles[0], key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # Extract iris region using the largest circle\n",
        "        x, y, r = circles[0]\n",
        "        iris_region = image[y - r:y + r, x - r:x + r]\n",
        "\n",
        "        # Normalize iris region (e.g., contrast enhancement, normalization)\n",
        "        normalized_iris = cv2.equalizeHist(iris_region)\n",
        "\n",
        "        # Resize the normalized iris region to a standard size\n",
        "        normalized_iris = cv2.resize(normalized_iris, (50, 100))\n",
        "\n",
        "        return normalized_iris.flatten()\n",
        "\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "reference_features = extract_features(reference_image_processed)\n",
        "probe_features = extract_features(probe_image_processed)\n",
        "\n",
        "# Match the features (e.g., using cosine similarity)\n",
        "if reference_features is not None and probe_features is not None:\n",
        "    similarity_score = np.sum(np.abs(reference_features - probe_features))\n",
        "    # Set a threshold for similarity score to classify as authorized or unauthorized\n",
        "    threshold = 500\n",
        "\n",
        "    # Classify as authorized or unauthorized based on the similarity score\n",
        "    if similarity_score <= threshold:\n",
        "        print(\"Authorized\")\n",
        "    else:\n",
        "        print(\"Unauthorized\")\n",
        "else:\n",
        "    print(\"Feature extraction failed. Unable to proceed.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAJDpISs9dB/7VHrCKnk/U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}